{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# !pip install gpxpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import csv, re, os, sys, gpxpy, folium\n",
    "from datetime import datetime, timedelta, date\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dir_path = './'\n",
    "in_dir_name = 'in_files'\n",
    "out_dir_name = 'out_files'\n",
    "time_tolerance = 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def init_dir():\n",
    "    dir_list = os.listdir(dir_path)\n",
    "    is_init = False\n",
    "    if in_dir_name not in dir_list:\n",
    "        print('作業ディレクトリが存在しません')\n",
    "        os.mkdir(dir_path + in_dir_name)\n",
    "        print('make: /' + in_dir_name)\n",
    "        is_init = True\n",
    "    if out_dir_name not in dir_list:\n",
    "        if not is_init:\n",
    "            print('作業ディレクトリが存在しません')\n",
    "        os.mkdir(dir_path + out_dir_name)\n",
    "        print('make: /' + out_dir_name)\n",
    "        is_init = True\n",
    "    if is_init:\n",
    "        print('初期化が完了しました')\n",
    "        sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def get_valid_num(pronpt='', get_int=True, max=100000):\n",
    "    num = 0\n",
    "    while True:\n",
    "        if pronpt != '':\n",
    "            print(pronpt)\n",
    "        num = input('>')\n",
    "        try:\n",
    "            num = float(num)\n",
    "            if num > max - 1 or num < 0:\n",
    "                print(f'0以上{max}未満の数を入力してください')\n",
    "                continue\n",
    "            else:\n",
    "                break\n",
    "        except ValueError:\n",
    "            print('数字を入力してください')\n",
    "            continue\n",
    "    if get_int:\n",
    "        return int(num)\n",
    "    else:\n",
    "        return num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def format_weather_data():\n",
    "    print('=' * 50)\n",
    "    print('*** 気象表作成 ***')\n",
    "    weather_datas = os.listdir(dir_path + in_dir_name)\n",
    "    weather_datas = [file for file in weather_datas if file.endswith(\".csv\")]\n",
    "    if len(weather_datas) == 0:\n",
    "        print(in_dir_name + 'に .csv ファイルが存在しません')\n",
    "        sys.exit(2)\n",
    "\n",
    "    print('使用する気象データファイルを選択')\n",
    "    for i in range(len(weather_datas)):\n",
    "        print(f'{i}) {weather_datas[i]}')\n",
    "    i_filename = weather_datas[get_valid_num(max=len(weather_datas))]\n",
    "    i_filename = dir_path + in_dir_name + '/' + i_filename\n",
    "    print()\n",
    "\n",
    "    with open(i_filename, 'r', encoding='MS932') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "\n",
    "        dl_date = ''\n",
    "        raw_data = []\n",
    "\n",
    "        for row_idx, row in enumerate(reader):\n",
    "            if row_idx == 0:\n",
    "                dl_date = row[0][row[0].find('：') + 1:]\n",
    "            if row_idx > 1:\n",
    "                raw_data.append(row)\n",
    "\n",
    "    get_md = lambda date: date[date.find('/') + 1:]\n",
    "    md_start = get_md(raw_data[5][0])  # Month/Day start ex: 3/17\n",
    "    md_end = get_md(raw_data[-1][0])  # Month/Day end ex: 3/19\n",
    "    y_start = raw_data[5][0][:raw_data[5][0].find('/')]  # year start\n",
    "    reference_years = 0\n",
    "    for row in raw_data:\n",
    "        if row[0].find(md_start) != -1:\n",
    "            reference_years += 1\n",
    "    reference_days = int((len(raw_data) - 5) / reference_years)\n",
    "\n",
    "    processed_data = {}\n",
    "    station_data = {}\n",
    "    invalid_di = []  # invalid date and item\n",
    "    get_loc = lambda li: raw_data[0][li] + '県' + raw_data[1][li] + '地方'  # li: line_index\n",
    "    loc = get_loc(1)\n",
    "    for line_idx in range(1, len(raw_data[0])):\n",
    "        if get_loc(line_idx) != loc:\n",
    "            processed_data.setdefault(loc, station_data.copy())\n",
    "            loc = get_loc(line_idx)\n",
    "            station_data.clear()\n",
    "        if raw_data[4][line_idx] == '':\n",
    "            row = []\n",
    "            for row_ix in range(5, len(raw_data)):\n",
    "                if re.match(r'^[-+]?[0-9]*\\.?[0-9]+$', raw_data[row_ix][line_idx]):\n",
    "                    row.append(float(raw_data[row_ix][line_idx]))\n",
    "                else:\n",
    "                    row.append(0)\n",
    "                    invalid_di.append('-'.join([raw_data[row_ix][0], loc, raw_data[2][line_idx]]))\n",
    "            station_data.setdefault(raw_data[2][line_idx], row)\n",
    "    processed_data.setdefault(loc, station_data.copy())\n",
    "\n",
    "    must_items = ['平均気温(℃)', '最高気温(℃)', '最低気温(℃)', '降水量の合計(mm)']\n",
    "    for mi in must_items:\n",
    "        if mi not in station_data.keys():\n",
    "            print(f'{i_filename} には観測項目【{mi}】が含まれていません\\n'\n",
    "                  f'気象データのダウンロードの設定を確認してください')\n",
    "            sys.exit(2)\n",
    "    if len(invalid_di) > 0:\n",
    "        print(f'{i_filename} には欠損データが検出されました\\n'\n",
    "              f'これらのデータを 0 で置換しました\\n'\n",
    "              f'HA, AA, LA, LL の数値が適切に計算できません\\n'\n",
    "              f'検出個所：')\n",
    "        for invalid in invalid_di:\n",
    "            print('\\t' + invalid)\n",
    "    else:\n",
    "        print(f'{i_filename} は適切に読み込まれました')\n",
    "    print('-' * 50)\n",
    "\n",
    "    site_infos = []  # site place name and elevation\n",
    "    obs_infos = []  # observation point elevation\n",
    "    defs = []\n",
    "\n",
    "    keys_obs = list(processed_data.keys())  # keys of observation points\n",
    "    for i in range(1, reference_days + 1):\n",
    "        print(f'【{i}日目】\\n観測地点を選択（半角数字）')\n",
    "        for j, locs in enumerate(keys_obs):\n",
    "            print(f'{j}) {locs}')\n",
    "        obs_choice = get_valid_num(max=len(keys_obs))\n",
    "        obs_point = keys_obs[obs_choice]\n",
    "        obs_place_elev = get_valid_num(pronpt=f'{obs_point}の標高を入力', get_int=False)\n",
    "        obs_infos.append((obs_point, obs_place_elev))\n",
    "\n",
    "        print('サイト地の名称を入力（ENTERで省略）')\n",
    "        site_place = input(' >')\n",
    "        if site_place == '':\n",
    "            site_place = str(i) + '日目サイト地'\n",
    "        site_place_elev = get_valid_num(pronpt=f'{site_place}の標高を入力', get_int=False)\n",
    "        site_infos.append((site_place, site_place_elev))\n",
    "        defs.append((site_infos[i - 1][1] - obs_infos[i - 1][1]) * -0.006)\n",
    "        print('-' * 50)\n",
    "\n",
    "    print('保存ファイル名を入力（ENTERで省略）')\n",
    "    o_filename = input('>')\n",
    "\n",
    "    if '降水量の合計(mm)' in station_data:\n",
    "        value_to_move = station_data['降水量の合計(mm)']\n",
    "        del station_data['降水量の合計(mm)']\n",
    "        station_data['降水量の合計(mm)'] = value_to_move\n",
    "\n",
    "    write_data = []  # write to csv data\n",
    "    write_data2 = [['', 'HH', 'HA', 'AA', 'LA', 'LL']]\n",
    "    md_start = datetime.strptime(md_start, '%m/%d')  # convert str to date\n",
    "    md_end = datetime.strptime(md_end, '%m/%d')\n",
    "    d = date(datetime.now().year, md_start.month, md_start.day)\n",
    "    if o_filename == '':\n",
    "        o_filename = f'{dir_path}{out_dir_name}/{md_start.strftime(\"%m%d\")}-{md_end.strftime(\"%m%d\")}-weatherTable.csv'\n",
    "    else:\n",
    "        o_filename = f'{dir_path}{out_dir_name}/{o_filename}.csv'\n",
    "    for i in range(reference_days):\n",
    "        write_data.append([d.strftime('%Y/%m/%d') + ' DAY ' + str(i + 1)])\n",
    "        write_data.append([f'観測地点：{obs_infos[i][0]} 標高：{obs_infos[i][1]}'])\n",
    "        write_data.append([f'基準地点：{site_infos[i][0]} 標高：{site_infos[i][1]} 補正値：{defs[i]}K'])\n",
    "        write_data.append([''] + [str(int(y_start) + j) for j in range(reference_years)])\n",
    "        table = []\n",
    "        table_crr = []\n",
    "        sa = [''] * 5  # sum and average HH, HA, AA, LA, HA\n",
    "        for item in station_data.keys():\n",
    "            table.append(\n",
    "                [item] + [processed_data.get(obs_infos[i][0]).get(item)[i + k * reference_days] for k in\n",
    "                          range(reference_years)])\n",
    "        for row in table:\n",
    "            if '℃' in row[0]:\n",
    "                table_crr = [round(row[elem_idx] + defs[i], 1) for elem_idx in range(1, len(row))]\n",
    "                write_data.append([row[0]] + table_crr)\n",
    "            else:\n",
    "                write_data.append(row)\n",
    "            if row[0] == '最高気温(℃)':\n",
    "                sa[0] = str(max(table_crr[1:]))\n",
    "                sa[1] = str(round(sum(table_crr[1:]) / reference_years, 1))\n",
    "            elif row[0] == '平均気温(℃)':\n",
    "                sa[2] = str(round(sum(table_crr[1:]) / reference_years, 1))\n",
    "            elif row[0] == '最低気温(℃)':\n",
    "                sa[4] = str(min(table_crr[1:]))\n",
    "                sa[3] = str(round(sum(table_crr[1:]) / reference_years, 1))\n",
    "        write_data2.append([d.strftime('%Y/%m/%d')] + sa)\n",
    "        d += timedelta(days=1)\n",
    "    write_data.append([])\n",
    "\n",
    "    with open(o_filename, 'w', newline='', encoding='MS932') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerows(write_data)\n",
    "        writer.writerows(write_data2)\n",
    "\n",
    "    print('\\n正常に終了しました')\n",
    "    print('=' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# author: https://aotoshiro.jpn.org/2021/2376\n",
    "def calc_dist(rlat_a, rlat_b, rlon_a, rlon_b):\n",
    "    A = 6378137.000  # WGS84測地系の楕円体の長半径a\n",
    "    B = 6356752.314  # WGS84測地系の楕円体の短半径b\n",
    "    E = np.sqrt((A ** 2 - B ** 2) / A ** 2)  # 離心率\n",
    "    Dy = rlat_a - rlat_b  # 2点の緯度(latitude)の差 [rad]\n",
    "    Dx = rlon_a - rlon_b  # 2点の経度(longitude)の差 [rad]\n",
    "    P = (rlat_a + rlat_b) / 2  # 2点の緯度(latitude)の平均 [rad]\n",
    "    W = np.sqrt(1 - E ** 2 * np.sin(P) ** 2)\n",
    "    M = A * (1 - E ** 2) / W ** 3  # 子午線曲率半径\n",
    "    N = A / W  # 卯酉線曲線半径\n",
    "    D = np.sqrt((Dy * M) ** 2 + (Dx * N * np.cos(P)) ** 2)\n",
    "    return D  # 2点間の距離 [m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def parse_ct(file_path):\n",
    "    column = ['date', 'time_str', 'time1', 'time2', 'time_passed', 'event', 'elev_spec']\n",
    "    data_list = []\n",
    "\n",
    "    prev_datetime = None\n",
    "\n",
    "    with open(file_path, 'r') as ct_file:\n",
    "        date_obj = None\n",
    "        pattern_date_title = r'(\\d{4}/\\d{1,2}/\\d{1,2}.*)'\n",
    "        pattern_date = r'(\\d{4}/\\d{1,2}/\\d{1,2})'\n",
    "        pattern_event = r'(\\d{1,2}:\\d{2},.*)'\n",
    "        pattern_event_rest = r'(\\d{1,2}:\\d{2}~\\d{1,2}:\\d{2},\\w+)'\n",
    "\n",
    "        time_passed = 0\n",
    "\n",
    "        for line in ct_file:\n",
    "            parts = line.split(',')\n",
    "            if len(parts) == 3:\n",
    "                time_str, event, elev = parts\n",
    "                elev = elev.strip()\n",
    "            elif len(parts) == 2:\n",
    "                time_str, event = parts\n",
    "                event = event.strip()\n",
    "                elev = -1019\n",
    "\n",
    "            if re.match(pattern_date_title, line):\n",
    "                date_str = re.match(pattern_date, line)[0]\n",
    "                date_obj = datetime.strptime(date_str, '%Y/%m/%d')\n",
    "\n",
    "            elif re.match(pattern_event, line):\n",
    "                time_obj = datetime.strptime(time_str, '%H:%M')\n",
    "                date_obj = datetime(date_obj.year, date_obj.month, date_obj.day, time_obj.hour, time_obj.minute)\n",
    "                if prev_datetime is not None:\n",
    "                    time_passed = (date_obj - prev_datetime).total_seconds() / 60\n",
    "                data_list.append([date_obj, time_str, time_str, None, time_passed, event, elev])\n",
    "                prev_datetime = date_obj\n",
    "\n",
    "            elif re.match(pattern_event_rest, line):\n",
    "                time1, time2 = time_str.split('~')\n",
    "                time_obj = datetime.strptime(time1, '%H:%M')\n",
    "                date_obj = datetime(date_obj.year, date_obj.month, date_obj.day, time_obj.hour, time_obj.minute)\n",
    "                time2_obj = datetime.strptime(time2, '%H:%M')\n",
    "                if prev_datetime is not None:\n",
    "                    time_passed = (date_obj - prev_datetime).total_seconds() / 60\n",
    "                data_list.append([date_obj, time_str, time1, time2, time_passed, event, elev])\n",
    "                prev_datetime = datetime(date_obj.year, date_obj.month, date_obj.day, time2_obj.hour, time2_obj.minute)\n",
    "\n",
    "    time_event_df = pd.DataFrame(data_list, columns=column)\n",
    "\n",
    "    return time_event_df\n",
    "\n",
    "\n",
    "def correct_ct(time_event_df, new_dir_name):\n",
    "    crt_ct_file_path = f'{dir_path}{out_dir_name}/{new_dir_name}/courseTime_{time_event_df.loc[0, \"date\"].date()}-{time_event_df.loc[len(time_event_df) - 1, \"date\"].date()}.txt'\n",
    "    with open(crt_ct_file_path, 'w', encoding='shift-jis') as ccf:  # ccf: correct_courseTime_file\n",
    "        prev_datetime = datetime(1910, 3, 17, 0, 0)\n",
    "        for index, row in time_event_df.iterrows():\n",
    "            if prev_datetime.date() != row['date'].date():\n",
    "                ccf.write(f'\\n{row[\"date\"].strftime(\"%Y/%m/%d\")}コースタイム\\n')\n",
    "            line_str = f'{row[\"time_str\"]},{row[\"event\"].strip()},{round(int(row[\"elev_calc\"]), -1)}'\n",
    "            if row['elev_spec'] != -1019:\n",
    "                line_str = f'{line_str}({row[\"elev_spec\"]})'\n",
    "            ccf.write(line_str + '\\n')\n",
    "            prev_datetime = row['date']\n",
    "\n",
    "\n",
    "def analyze_ct(time_event_df, new_dir_name):\n",
    "    analytics_file_path = f'{dir_path}{out_dir_name}/{new_dir_name}/courseTimeAnalytics_{time_event_df.loc[0, \"date\"].date()}-{time_event_df.loc[len(time_event_df) - 1, \"date\"].date()}.csv'\n",
    "    to_csv_df = time_event_df[\n",
    "        ['date', 'time_str', 'time_passed', 'event', 'elev_spec', 'elev_calc', 'lat', 'lon', 'dist']]\n",
    "    to_csv_df.to_csv(analytics_file_path, index=True, encoding='utf-8')\n",
    "    return 0\n",
    "\n",
    "\n",
    "class GPXDataAnalyzer:\n",
    "    def __init__(self, gpx_file_path):\n",
    "        self.gpx_file_path = gpx_file_path\n",
    "        self.gpx_data = self.load_gpx_data()\n",
    "\n",
    "    def load_gpx_data(self):\n",
    "        with open(self.gpx_file_path, 'r', encoding='utf-8') as gpx_file:\n",
    "            gpx = gpxpy.parse(gpx_file)\n",
    "            return gpx\n",
    "\n",
    "    # def linear_interpolation(self, point1, point2, target_time):\n",
    "    #     time1 = point1.time.timestamp()\n",
    "    #     time2 = point2.time.timestamp()\n",
    "    #     value1 = point1.elevation  # 例: 高度データ\n",
    "    #     value2 = point2.elevation  # 例: 高度データ\n",
    "    #\n",
    "    #     interpolated_value = value1 + (value2 - value1) * ((target_time - time1) / (time2 - time1))\n",
    "    #     return interpolated_value\n",
    "\n",
    "    def search_gpx_data_by_time(self, target_time_jst, time_tolerance):\n",
    "        closest_point = None\n",
    "        closest_time_diff = None\n",
    "\n",
    "        jst_offset = timedelta(hours=9)  # JSTとUTCの固定オフセット\n",
    "        target_time_utc = target_time_jst - jst_offset  # JSTからUTCに変換\n",
    "        for track in self.gpx_data.tracks:\n",
    "            for segment in track.segments:\n",
    "                for point in segment.points:\n",
    "                    if point.time:\n",
    "                        time_diff = abs((point.time.replace(tzinfo=None) - target_time_utc).total_seconds())\n",
    "                        if closest_point is None or time_diff < closest_time_diff:\n",
    "                            closest_point = point\n",
    "                            closest_time_diff = time_diff\n",
    "\n",
    "        if closest_point and closest_time_diff <= time_tolerance:\n",
    "            return closest_point\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "\n",
    "def plot_ct():\n",
    "    print('=' * 50)\n",
    "    print('*** コースタイム・軌跡分析 ***')\n",
    "\n",
    "    in_datas = os.listdir(dir_path + '/' + in_dir_name)\n",
    "    gpx_datas = [file for file in in_datas if file.endswith(\".gpx\")]\n",
    "    ct_datas = [file for file in in_datas if file.endswith(\".txt\")]\n",
    "    if len(gpx_datas) == 0:\n",
    "        print(in_dir_name + 'に .gpx ファイルが存在しません')\n",
    "        sys.exit(3)\n",
    "    if len(ct_datas) == 0:\n",
    "        print(in_dir_name + 'に .txt ファイルが存在しません')\n",
    "        sys.exit(3)\n",
    "\n",
    "    print('使用するGPXデータファイルを選択')\n",
    "    for i in range(len(gpx_datas)):\n",
    "        print(f'{i}) {gpx_datas[i]}')\n",
    "    gpx_filename = gpx_datas[get_valid_num(max=len(gpx_datas))]\n",
    "    gpx_file_path = dir_path + in_dir_name + '/' + gpx_filename\n",
    "    print('-' * 50)\n",
    "    print('使用するコースタイムファイルを選択')\n",
    "    for i in range(len(ct_datas)):\n",
    "        print(f'{i}) {ct_datas[i]}')\n",
    "    ct_filename = ct_datas[get_valid_num(max=len(ct_datas))]\n",
    "    ct_file_path = dir_path + in_dir_name + '/' + ct_filename\n",
    "    print('-' * 50)\n",
    "\n",
    "    time_event_df = parse_ct(ct_file_path)\n",
    "    print(f'{ct_file_path} は適切に読み込まれました')\n",
    "    analyzer = GPXDataAnalyzer(gpx_file_path)\n",
    "    print(f'{gpx_file_path} は適切に読み込まれました')\n",
    "    print('-' * 50)\n",
    "\n",
    "    lat_list = []\n",
    "    lon_list = []\n",
    "    elev_list = []\n",
    "    for event in time_event_df['date']:\n",
    "        closest_point = analyzer.search_gpx_data_by_time(event, time_tolerance)\n",
    "        lat_list.append(closest_point.latitude)\n",
    "        lon_list.append(closest_point.longitude)\n",
    "        elev_list.append(closest_point.elevation)\n",
    "    time_event_df['elev_calc'] = elev_list\n",
    "    time_event_df['lat'] = lat_list\n",
    "    time_event_df['lon'] = lon_list\n",
    "\n",
    "    dist = []\n",
    "    rlat_a, rlon_a = 0, 0\n",
    "    for index, row in time_event_df.iterrows():\n",
    "        if index == 0:\n",
    "            dist.append(0)\n",
    "            rlat_a = np.radians(row['lat'])\n",
    "            rlon_a = np.radians(row['lon'])\n",
    "        else:\n",
    "            dist.append(calc_dist(rlat_a, np.radians(row['lat']), rlon_a, np.radians(row['lon'])))\n",
    "            rlat_a = np.radians(row['lat'])\n",
    "            rlon_a = np.radians(row['lon'])\n",
    "    time_event_df['dist'] = dist\n",
    "\n",
    "    # pd.set_option('display.max_rows', None)\n",
    "    # pd.set_option('display.max_columns', None)\n",
    "    # print(time_event_df)\n",
    "\n",
    "    map_center = [time_event_df.loc[0, 'lat'], time_event_df.loc[0, 'lon']]\n",
    "    gpx_map = folium.Map(tiles='http://cyberjapandata.gsi.go.jp/xyz/std/{z}/{x}/{y}.png', attr='© GSI Japan',\n",
    "                         location=map_center, zoom_start=15)\n",
    "\n",
    "    for track in analyzer.gpx_data.tracks:\n",
    "        for segment in track.segments:\n",
    "            folium.PolyLine(\n",
    "                locations=[(point.latitude, point.longitude) for point in segment.points],\n",
    "                color='blue'\n",
    "            ).add_to(gpx_map)\n",
    "\n",
    "    for index, row in time_event_df.iterrows():\n",
    "        marker = folium.Marker(\n",
    "            location=[row['lat'], row['lon']],\n",
    "            tooltip=f'{row[\"date\"].strftime(\"%m/%d\")} {row[\"time_str\"]} {row[\"event\"].strip()}: {round(int(row[\"elev_calc\"]), -1)}m',\n",
    "            icon=folium.Icon(color='blue')\n",
    "        )\n",
    "        marker.add_to(gpx_map)\n",
    "\n",
    "    new_dir_name = f'{time_event_df.loc[0, \"date\"].date()}-{time_event_df.loc[len(time_event_df) - 1, \"date\"].date()}'\n",
    "    if new_dir_name not in os.listdir(dir_path + out_dir_name):\n",
    "        os.mkdir(f'{dir_path}{out_dir_name}/{new_dir_name}')\n",
    "\n",
    "    map_file_path = f'{dir_path}{out_dir_name}/{new_dir_name}/courseTimeMap_{time_event_df.loc[0, \"date\"].date()}-{time_event_df.loc[len(time_event_df) - 1, \"date\"].date()}.html'\n",
    "    gpx_map.save(map_file_path)\n",
    "    correct_ct(time_event_df, new_dir_name)\n",
    "    analyze_ct(time_event_df, new_dir_name)\n",
    "\n",
    "    print(f'{dir_path}{out_dir_name}/{new_dir_name} に結果を保存しました\\n')\n",
    "    print('正常に終了しました')\n",
    "    print('=' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def parce_gpx(gpx_file_path):\n",
    "    column = ['day', 'lat', 'lon', 'name', 'd_h', 'd_t', 'd_dist', 'h', 't']\n",
    "    data_list = []\n",
    "    d_t_max = 36000  # 10h\n",
    "\n",
    "    gpx_data = None\n",
    "    with open(gpx_file_path, 'r', encoding='utf-8') as gpx_file:\n",
    "        gpx_data = gpxpy.parse(gpx_file)\n",
    "\n",
    "    is_1st = True\n",
    "    prev_point = None\n",
    "    prev_date = None\n",
    "    rlat_a, rlon_a = 0, 0\n",
    "    day = 1\n",
    "    for track in gpx_data.tracks:\n",
    "        for segment in track.segments:\n",
    "            for point in segment.points:\n",
    "                jst_date = point.time + timedelta(hours=9)\n",
    "                if is_1st:\n",
    "                    data_list.append(\n",
    "                        [day, point.latitude, point.longitude, point.name, 0, timedelta(0), 0, point.elevation,\n",
    "                         jst_date])\n",
    "                    is_1st = False\n",
    "                else:\n",
    "                    d_h = point.elevation - prev_point.elevation\n",
    "                    d_t = jst_date - prev_date\n",
    "                    d_dist = calc_dist(rlat_a, np.radians(point.latitude), rlon_a, np.radians(point.longitude))\n",
    "                    if d_t.total_seconds() > d_t_max:\n",
    "                        day += 1\n",
    "                        d_t = timedelta(0)\n",
    "                    data_list.append(\n",
    "                        [day, point.latitude, point.longitude, point.name, d_h, d_t, d_dist, point.elevation, jst_date])\n",
    "\n",
    "                prev_point = point\n",
    "                prev_date = jst_date\n",
    "                rlat_a, rlon_a = np.radians(point.latitude), np.radians(point.longitude)\n",
    "\n",
    "    gpx_df = pd.DataFrame(data_list, columns=column)\n",
    "\n",
    "    # pd.set_option('display.max_rows', None)\n",
    "    # pd.set_option('display.max_columns', None)\n",
    "    # print(gpx_df)\n",
    "\n",
    "    return gpx_df\n",
    "\n",
    "\n",
    "def sum_each_delta(gpx_df):\n",
    "    column = ['day', 'lat', 'lon', 'name', 'd_up', 'd_down', 'd_t', 'd_dist', 't', 'h']\n",
    "    data_list = []\n",
    "\n",
    "    get_1st_pwn = False  # get 1st point with name\n",
    "    d_up, d_down, d_t, d_dist = 0, 0, timedelta(0), 0\n",
    "    for index, row in gpx_df.iterrows():\n",
    "        if not get_1st_pwn and not row['name'] is None:\n",
    "            data_list.append(\n",
    "                [row['day'], row['lat'], row['lon'], row['name'], 0, 0, timedelta(0), 0, row['t'], row['h']])\n",
    "            get_1st_pwn = True\n",
    "        else:\n",
    "            if row['d_h'] > 0:\n",
    "                d_up += row['d_h']\n",
    "            else:\n",
    "                d_down -= row['d_h']\n",
    "            d_t = d_t + row['d_t']\n",
    "            d_dist += row['d_dist']\n",
    "\n",
    "            if not row['name'] is None:\n",
    "                data_list.append(\n",
    "                    [row['day'], row['lat'], row['lon'], row['name'], d_up, d_down, d_t, d_dist, row['t'], row['h']])\n",
    "                d_up, d_down, d_t, d_dist = 0, 0, timedelta(0), 0\n",
    "\n",
    "    name_point_df = pd.DataFrame(data_list, columns=column)\n",
    "\n",
    "    # pd.set_option('display.max_rows', None)\n",
    "    # pd.set_option('display.max_columns', None)\n",
    "    # print(name_point_df)\n",
    "    # name_point_df.to_csv('output.csv', index=False, encoding='MS932')\n",
    "\n",
    "    return name_point_df\n",
    "\n",
    "\n",
    "def print_ct(name_point_df):\n",
    "    day = 1\n",
    "    is_1st = True\n",
    "    print_list = []\n",
    "    d_sum_dist, d_sum_t, d_sum_up, d_sum_down = 0, timedelta(0), 0, 0\n",
    "    for index, row in name_point_df.iterrows():\n",
    "        time = row[\"t\"].strftime(\"%m/%d\")\n",
    "        d_t = int(row[\"d_t\"].total_seconds() / 60)\n",
    "        name = re.sub(r'\\s*\\[.*\\]\\s*', '', row['name'])\n",
    "        if is_1st:\n",
    "            print_list.append(f'【{time} day{day}】')\n",
    "            print_list.append(f'{name} ({int(row[\"h\"])}m)')\n",
    "            is_1st = False\n",
    "        else:\n",
    "            if not row['day'] == day or index == len(name_point_df) - 1:\n",
    "                last_point = print_list[-1]\n",
    "\n",
    "                total_seconds = d_sum_t.total_seconds()\n",
    "                hours, seconds = divmod(total_seconds, 3600)\n",
    "                minutes, seconds = divmod(seconds, 60)\n",
    "                formatted_time = f\"{int(hours)}時間{int(minutes)}分\"\n",
    "                print_list.append(\n",
    "                    f'\\n実動距離：{int(d_sum_dist / 100) / 10}km 実動時間：{formatted_time} 行動時間：時間分')\n",
    "                print_list.append(f'▲{d_sum_up}▼{d_sum_down}')\n",
    "\n",
    "                if not index == len(name_point_df) - 1:\n",
    "                    day = row['day']\n",
    "                    print_list.append(f'\\n\\n【{time} day{day}】')\n",
    "                    print_list.append(last_point)\n",
    "                    print_list.append(\n",
    "                        f'\\n ↓ {int(row[\"d_dist\"])}m/{d_t}min ▲{int(row[\"d_up\"])}▼{int(row[\"d_down\"])}')\n",
    "                    print_list.append(f'\\n{name} ({int(row[\"h\"])}m)')\n",
    "                    d_sum_dist, d_sum_t, d_sum_up, d_sum_down = 0, timedelta(0), 0, 0\n",
    "            else:\n",
    "                d_sum_dist += row['d_dist']\n",
    "                d_sum_t += row['d_t']\n",
    "                d_sum_up += row['d_up']\n",
    "                d_sum_down += row['d_down']\n",
    "                print_list.append(\n",
    "                    f'\\n ↓ {int(row[\"d_dist\"])}m/{d_t}min ▲{int(row[\"d_up\"])}▼{int(row[\"d_down\"])}')\n",
    "                print_list.append(f'\\n{name} ({int(row[\"h\"])}m)')\n",
    "\n",
    "    out_file_path = f'{dir_path}{out_dir_name}/{datetime.now().strftime(\"%Y%m%d %H-%M-%S\")}.txt'\n",
    "    with open(out_file_path, \"w\") as file:\n",
    "        for item in print_list:\n",
    "            file.write(item + \"\\n\")\n",
    "    print(f'{out_file_path} に結果を保存しました\\n')\n",
    "\n",
    "\n",
    "# ヤマレコでルートを計画すると経由地点の名称入りgpxファイルが得られる。これを利用して企画書用のコースタイムを一括で作成できるプログラムを組もうかと思ったが、山頂などの標高誤差が大きすぎて実用的でないため中止。残念でしたー\n",
    "def make_ct_string():\n",
    "    print('=' * 50)\n",
    "    print('*** 企画書用コースタイム作成 ***')\n",
    "\n",
    "    in_datas = os.listdir(dir_path + '/' + in_dir_name)\n",
    "    gpx_datas = [file for file in in_datas if file.endswith(\".gpx\")]\n",
    "    if len(gpx_datas) == 0:\n",
    "        print(in_dir_name + 'に .gpx ファイルが存在しません')\n",
    "        sys.exit(4)\n",
    "\n",
    "    print('使用するGPXデータファイルを選択')\n",
    "    for i in range(len(gpx_datas)):\n",
    "        print(f'{i}) {gpx_datas[i]}')\n",
    "    gpx_filename = gpx_datas[get_valid_num(max=len(gpx_datas))]\n",
    "    gpx_file_path = dir_path + in_dir_name + '/' + gpx_filename\n",
    "    print('-' * 50)\n",
    "\n",
    "    gpx_df = parce_gpx(gpx_file_path)\n",
    "    print(f'{gpx_file_path} は適切に読み込まれました')\n",
    "    print('-' * 50)\n",
    "\n",
    "    name_point_df = sum_each_delta(gpx_df)\n",
    "    print_ct(name_point_df)\n",
    "\n",
    "    print('正常に終了しました')\n",
    "    print('=' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用する機能を選択\n",
      "0) 気象表作成\n",
      "1) コースタイム・軌跡分析\n",
      "2) 企画書用コースタイム作成 (β)\n",
      "数字を入力\n",
      "==================================================\n",
      "*** 気象表作成 ***\n",
      "使用する気象データファイルを選択\n",
      "0) data (13).csv\n",
      "1) data (8).csv\n",
      "\n",
      "./in_files/data (8).csv は適切に読み込まれました\n",
      "--------------------------------------------------\n",
      "【1日目】\n",
      "観測地点を選択（半角数字）\n",
      "0) 福島県桧枝岐地方\n",
      "0以上1未満の数を入力してください\n",
      "0以上1未満の数を入力してください\n",
      "0以上1未満の数を入力してください\n",
      "福島県桧枝岐地方の標高を入力\n",
      "サイト地の名称を入力（ENTERで省略）\n",
      "0の標高を入力\n",
      "--------------------------------------------------\n",
      "保存ファイル名を入力（ENTERで省略）\n",
      "\n",
      "正常に終了しました\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    init_dir()\n",
    "\n",
    "    print('使用する機能を選択')\n",
    "    features = [\n",
    "        '気象表作成',\n",
    "        'コースタイム・軌跡分析',\n",
    "        '企画書用コースタイム作成 (β)'\n",
    "    ]\n",
    "    for i in range(len(features)):\n",
    "        print(f'{i}) {features[i]}')\n",
    "    feature_choice = get_valid_num(pronpt='数字を入力', max=len(features))\n",
    "\n",
    "    if feature_choice == 0:\n",
    "        format_weather_data()\n",
    "    elif feature_choice == 1:\n",
    "        plot_ct()\n",
    "    elif feature_choice == 2:\n",
    "        make_ct_string()\n",
    "except SystemExit:\n",
    "    print('\\nプログラムを終了します')\n",
    "\n",
    "    print('=' * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
